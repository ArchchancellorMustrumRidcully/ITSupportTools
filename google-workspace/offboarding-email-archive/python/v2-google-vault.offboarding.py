#!/usr/bin/env python3
from urllib import request
import requests
import json
import sys
from requests.utils import requote_uri
from urllib.parse import urlencode, quote_plus
import urllib
import shutil
import time
import os
import mimetypes

google_cloud_client_id=os.environ['google_cloud_client_id']
google_cloud_client_secret=os.environ['google_cloud_client_secret']
google_cloud_refresh_token=os.environ['google_cloud_refresh_token']

user_list=[""]
admin_users=[""]
root_folder_id=""

matter={
	"user": "",
	"matterId": "",
	"savedQueryId": "",
	"exportId": ""
}

google_oauth_base_url="https://www.googleapis.com"
google_vault_base_url="https://vault.googleapis.com"
google_drive_base_url="https://www.googleapis.com"
google_storage_base_url="https://storage.googleapis.com"

def generate_google_access_token(google_cloud_client_id,google_cloud_client_secret,refresh_Token):

        url = f"{google_oauth_base_url}/oauth2/v4/token"

        headers = {
        "Accept" : "application/json",
        }

        body = {
        "client_id": google_cloud_client_id,
        "client_secret": google_cloud_client_secret,
        "refresh_token": refresh_Token,
        "grant_type": "refresh_token"
        }

        response = requests.post(url, headers=headers, json=body)
        response.raise_for_status()

        apiResponse = response.json()
        access_Token = apiResponse["access_token"]
        return access_Token

def generate_matter(user,matter):

        url = f"{google_vault_base_url}/v1/matters/"

        body = {           
        "state": "OPEN",
        "description": "Generated by Python",
        "name": user + "'s archive"
        }

        response = session.post(url, json=body)
        response.raise_for_status()

        apiResponse = response.json()
        matterId=apiResponse["matterId"]

        matter["user"]=user
        matter["matterId"]=matterId
        return matter

def generate_search_query(user,matter):

        user=matter["user"]
        matterId=matter["matterId"]

        url = f"{google_vault_base_url}v1/matters/{matterId}/savedQueries"

        body = {
            "displayName": user + "'s email search query",
            "query": {
                "corpus": "MAIL",
                "dataScope": "ALL_DATA",
                "searchMethod": "ACCOUNT",
                "accountInfo": { "emails": [user]},
                "mailOptions": {"excludeDrafts" : "false"},
                "timeZone": "Atlantic/Canary",
                "method": "ACCOUNT"
        }}

        response = session.post(url, json=body)
        response.raise_for_status()

        apiResponse = response.json()
        savedQueryId=apiResponse["savedQueryId"]

        matter["savedQueryId"]=savedQueryId
        return matter

def generate_export(user,matter):

        user=matter["user"]
        matterId=matter["matterId"]

        url = f"{google_vault_base_url}/v1/matters/{matterId}/exports"

        body = {
                "name": user + "'s Export",
                "query": {
                    "corpus": "MAIL",
                    "dataScope": "ALL_DATA",
                    "searchMethod": "ACCOUNT",
                    "accountInfo": { "emails": [user]},
                    "mailOptions": {"excludeDrafts" : "false"},
                    "timeZone": "Atlantic/Canary",
                    "method": "Account",
                },
                "exportOptions": {
                    "mailOptions": {
                        "exportFormat": "MBOX",
                        "showConfidentialModeContent": "true"
                    },
                    "region": "any"
                    }
                }
        
        response = session.post(url, json=body)
        response.raise_for_status()

        apiResponse=response.json()
        exportId=apiResponse["id"]

        matter["exportId"]=exportId
        return matter

def set_vault_permissions(admin,matter):

        matterId=matter["matterId"]

        url = f"{google_vault_base_url}v1/matters/{matterId}:addPermissions"

        body = {
            "matterPermission": 
        {
            "role": "COLLABORATOR",
            "accountId": admin
        },
            "sendEmails": "false",
            "ccMe": "false"
        }

        response = session.post(url, json=body)
        response.raise_for_status()

        apiResponse=response.json()
        return apiResponse

def get_export_status(matter):

        matterId=matter["matterId"]   
        exportId=matter["exportId"]

        url = f"{google_vault_base_url}/v1/matters/{matterId}/exports/"
        
        response = session.get(url)
        response.raise_for_status()

        apiResponse=response.json()
        status=apiResponse["exports"][0]["status"]

        while status == "IN_PROGRESS":

                response = session.get(url)
                response.raise_for_status()

                apiResponse=response.json()
                status=apiResponse["exports"][0]["status"]
                print("Export is not completed yet. Going to sleep for 30 seconds, then I will check the export status again")
                time.sleep(30)

        if status == "COMPLETED":

            cloudStorageSink=apiResponse["exports"][0]["cloudStorageSink"]["files"]

        return cloudStorageSink

def download_export(objectName,bucketName,size,md5Hash,user):
        
        encoded=urllib.parse.quote(objectName,safe='')
        download_url=f"{google_storage_base_url}/storage/v1/b/{bucketName}/o/{encoded}?alt=media"
        directory=user
        parent_dir="downloads"
        path = os.path.join(parent_dir, directory)
        os.makedirs(path, exist_ok=True)
        last = objectName.split("/")[-1]
        fileName=(path+"/"+last)

        with session.get(download_url, stream=True) as r:
                PreparedResponse=requests.get
                with open(fileName, 'wb') as f:
                    shutil.copyfileobj(r.raw, f, length=16*1024*1024)
                    r.raise_for_status()

        return fileName

def create_folder(user,rootFolderId,access_Token):
            
        folder_metadata = {
        'name' : user,
        'parents' : [rootFolderId],
        'mimeType' : 'application/vnd.google-apps.folder'
        }

        url=f"{google_drive_base_url}/upload/drive/v3/files?uploadType=multipart&supportsAllDrives=true"

        headers={
            "Authorization": "Bearer " + access_Token
        }

        files = {
            'data': ('metadata', json.dumps(folder_metadata), "application/json; charset=UTF-8"),
        }

        response = requests.post(url=url, headers=headers, files=files)
        response.raise_for_status()

        apiResponse=response.json()
        print(apiResponse)
        archiveUserFolderId=apiResponse["id"]
        return archiveUserFolderId

def upload_matter(user,localFileName,archiveUserFolderId,access_Token):

        absoluteFileName=localFileName.split("/")[-1]

        file_metadata={

            'name': absoluteFileName, 
            "parents": 
                [ archiveUserFolderId ]

            }

        url=f"{google_drive_base_url}/upload/drive/v3/files?uploadType=multipart&supportsAllDrives=true"

        headers={
            "Authorization": "Bearer " + access_Token
        }

        with open(localFileName, 'rb') as file_to_upload:
            type=mimetypes.guess_type(localFileName,strict=True)
            files = {
            'data': ('metadata', json.dumps(file_metadata), "application/json; charset=UTF-8"),
            'file': ('mimeType', file_to_upload)
                }
            response = requests.post(url=url, headers=headers, files=files)
            response.raise_for_status()

        apiResponse=response.json()
        print(apiResponse)
        archiveUserFileId=apiResponse["id"]
        return archiveUserFileId

def delete_local_folder_file(localFileName):

        os.remove(localFileName)
        print(localFileName+" File Deleted")

def notify_user(archiveUserFolderId):

        url=f"https://drive.google.com/drive/folders/{archiveUserFolderId}"
        return url

for user in user_list:

    access_Token=generate_google_access_token(google_cloud_client_id,google_cloud_client_secret,google_cloud_refresh_token)

    headers = {
        "Accept" : "application/json",
        "Content-Type" : "application/json",
        "Authorization": "Bearer " + access_Token
    }

    session = requests.Session()
    session.headers.update(headers)

    matterStateMatterInfo=generate_matter(user,matter)

    matterStateSavedQueryId=generate_search_query(user,matter)

    matterStateExportId=generate_export(user,matter)

    archiveUserFolderId=create_folder(user,root_folder_id,access_Token)
    
    exportInfo=get_export_status(matterStateExportId)

    for each in exportInfo:

        objectName=each["objectName"]
        bucketName=each["bucketName"]
        size=each["size"]
        md5Hash=each["md5Hash"]
	
        access_Token=generate_google_access_token(google_cloud_client_id,google_cloud_client_secret,google_cloud_refresh_token)
	
        headers = {
		"Accept" : "application/json",
		"Content-Type" : "application/json",
		"Authorization": "Bearer " + access_Token
    	}
		
        session.headers.update(headers)

        localFileName=download_export(objectName,bucketName,size,md5Hash,user)

        uploaded_File=upload_matter(user,localFileName,archiveUserFolderId,access_Token)

        delete_local_folder_file(localFileName)

    print("Export uploaded to "+notify_user(archiveUserFolderId))

    print(matter)

    for adminId in admin_users:

        matterStateAdminPermissions=set_vault_permissions(adminId,matter)
